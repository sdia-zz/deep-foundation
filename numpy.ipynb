{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Foundational Exercise\n",
    "\n",
    "\n",
    "[Original source](https://iamtrask.github.io/2015/07/12/basic-python-network/)\n",
    "\n",
    "\n",
    "The idea is to be able to build this network from memory... No excuses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_linear(x, diff=False):\n",
    "    if diff:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(- x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "Y = np.array([[0,0,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16595599],\n",
       "       [ 0.44064899],\n",
       "       [-0.99977125]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "W = 2 * np.random.random((3, 1)) - 1\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    layer0 = X\n",
    "    layer1 = non_linear(np.dot(layer0, W))\n",
    "    loss = Y - layer1\n",
    "\n",
    "    gradient = loss * non_linear(layer1, diff=True)\n",
    "    \n",
    "    W += np.dot(layer0.T, gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00553603],\n",
       "       [0.00451114],\n",
       "       [0.99632027],\n",
       "       [0.99548341]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_linear(np.dot(X, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00966336],\n",
       "       [0.00786382],\n",
       "       [0.99359004],\n",
       "       [0.99212055]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def non_linear(x, diff=False):\n",
    "    if diff:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "Y = np.array([[0,0,1,1]]).T\n",
    "W = np.random.random((3,1))              \n",
    "\n",
    "for i in range(10000):\n",
    "    layer0 = X\n",
    "    layer1 = non_linear(np.dot(layer0, W))\n",
    "    loss = Y - layer1\n",
    "    gradient = loss * non_linear(layer1, diff=True)\n",
    "    W += np.dot(layer0.T, gradient)\n",
    "\n",
    "non_linear(np.dot(X, W))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00967088],\n",
       "       [0.00786211],\n",
       "       [0.99359268],\n",
       "       [0.99211594]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def non_linear(x, diff=False):\n",
    "    if diff:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "Y = np.array([[0,0,1,1]]).T\n",
    "W = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "for i in range(10000):\n",
    "    layer0 = X\n",
    "    layer1 = non_linear(np.dot(layer0, W))\n",
    "    loss = Y - layer1\n",
    "    gradient = loss * non_linear(layer1, diff=True)\n",
    "    W += np.dot(layer0.T, gradient)\n",
    "\n",
    "non_linear(np.dot(X, W))   \n",
    "\n",
    "\n",
    "# loss.shape     4,1\n",
    "# X.shape        4,3\n",
    "# Y.shape        4,1\n",
    "# gradient.shape 4,1\n",
    "# non_linear(layer1, diff=True)    4,1\n",
    "# W.shape        3,1  +=  X(T).gradient = (3,4).(4,1)\n",
    "# layer1.shape   4,1  ----- X.W = (4,3).(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0096673 ],\n",
       "       [0.00786552],\n",
       "       [0.9935889 ],\n",
       "       [0.99211764]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def non_linear(x, diff=False):\n",
    "    if diff:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "Y = np.array([[0,0,1,1]]).T\n",
    "W = 2 * np.random.random((3,1)) - 1\n",
    "for i in range(10000):\n",
    "    l0 = X\n",
    "    l1 = non_linear(np.dot(l0, W))\n",
    "    loss = Y - l1\n",
    "    gradient = loss * non_linear(l1, diff=True)\n",
    "    W += np.dot(l0.T, gradient)\n",
    "non_linear(np.dot(X, W))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00966564],\n",
       "       [0.0078644 ],\n",
       "       [0.99358977],\n",
       "       [0.99211894]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nl(x, diff=False):\n",
    "    if diff:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "Y = np.array([[0,0,1,1]]).T\n",
    "W = 2 * np.random.random((3,1)) - 1\n",
    "for i in range(10000):\n",
    "    l0 = X\n",
    "    l1 = nl(np.dot(l0, W))\n",
    "    loss = Y - l1\n",
    "    grad = loss * nl(l1, diff=True)\n",
    "    W += np.dot(l0.T, grad)\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00770514],\n",
       "       [0.00558998],\n",
       "       [0.99556246],\n",
       "       [0.99388069]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def nl(x, diff=False):\n",
    "    if diff:\n",
    "        return x * (1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x=np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "w = 10 * np.random.random((3,1))\n",
    "for i in range(10000):\n",
    "    l0=x\n",
    "    l1=nl(np.dot(l0,w))\n",
    "    # print(l1)\n",
    "    loss=y-l1\n",
    "    grad=loss*nl(l1, diff=True)\n",
    "    w+=np.dot(l0.T, grad)\n",
    "l1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00966743],\n",
       "       [0.00786382],\n",
       "       [0.99359057],\n",
       "       [0.99211788]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "\n",
    "def nl(x, diff=False):\n",
    "    if diff:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([[0,0,1], \n",
    "              [1,0,1], \n",
    "              [0,1,1], \n",
    "              [1,1,1]])\n",
    "\n",
    "Y = np.array([[0,0,1,1]]).T\n",
    "W = 2 * np.random.random((3,1)) - 1\n",
    "for i in range(10000):\n",
    "    l0 = X\n",
    "    l1 = nl(np.dot(X, W))\n",
    "    loss = Y-l1\n",
    "    grad = loss * nl(l1, diff=True)\n",
    "    W += np.dot(l0.T, grad)\n",
    "l1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00967043],\n",
       "       [0.9935892 ],\n",
       "       [0.00786562],\n",
       "       [0.99211555]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x, diff=False):\n",
    "    if diff:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([[0,0,1], \n",
    "              [1,0,1], \n",
    "              [0,1,1], \n",
    "              [1,1,1]])\n",
    "Y = np.array([[0,1,0,1]]).T\n",
    "W = 2 * np.random.random((3,1)) - 1\n",
    "for i in range(10000):\n",
    "    l0 = X\n",
    "    l1 = nl(np.dot(X,W))\n",
    "    loss = Y-l1\n",
    "    grad = loss * nl(l1, diff=True)\n",
    "    W += np.dot(l0.T, grad)\n",
    "l1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0096702 ],\n",
       "       [0.99358983],\n",
       "       [0.00786494],\n",
       "       [0.99211583]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x, diff=False):\n",
    "    if diff:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],\n",
    "            [1,0,1],\n",
    "            [0,1,1],\n",
    "            [1,1,1]])\n",
    "y = np.array([[0,1,0,1]]).T\n",
    "w = 2*np.random.random((3,1))-1\n",
    "for i in range(10000):\n",
    "    l0=x\n",
    "    l1=nl(np.dot(x,w))\n",
    "    loss = y-l1\n",
    "    grad = loss*nl(l1, diff=True)\n",
    "    w+=np.dot(l0.T, grad)\n",
    "l1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99357842],\n",
       "       [0.99833792],\n",
       "       [0.99764883],\n",
       "       [0.9993933 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x, d=0):\n",
    "    if d: return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[1,1,1,1]]).T\n",
    "w=2*np.random.random((3,1))-1\n",
    "for i in range(10000):\n",
    "    l0=x\n",
    "    l1=nl(np.dot(x,w))\n",
    "    loss = y-l1\n",
    "    grad = loss*nl(l1, d=1)\n",
    "    w+=np.dot(x.T, grad)\n",
    "l1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00966599],\n",
       "       [0.00786474],\n",
       "       [0.99358948],\n",
       "       [0.99211865]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x, d=0):\n",
    "    if d: return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,0,1,1]]).T\n",
    "w=np.random.random((3,1))\n",
    "for i in range(10000):\n",
    "    l0=x\n",
    "    l1=nl(np.dot(x,w))\n",
    "    loss=y-l1\n",
    "    grad=loss*nl(l1,d=1)\n",
    "    w+=np.dot(x.T,grad)\n",
    "l1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00966837],\n",
       "       [0.00786511],\n",
       "       [0.99358944],\n",
       "       [0.99211701]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x,d=0):\n",
    "    if d: return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,0,1,1]]).T\n",
    "w=np.random.random((3,1))\n",
    "for i in range(10000):\n",
    "    l1=nl(np.dot(x,w))\n",
    "    loss=y-l1\n",
    "    grad=loss*nl(l1,d=1)\n",
    "    w+=np.dot(x.T,grad)\n",
    "l1    \n",
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00966377],\n",
       "       [0.00786417],\n",
       "       [0.99358975],\n",
       "       [0.99212022]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x,d=0):\n",
    "    if d:return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,0,1,1]]).T\n",
    "w=np.random.random((3,1))\n",
    "for i in range(10000):\n",
    "    l1=nl(np.dot(x,w))\n",
    "    loss=y-l1\n",
    "    grad=loss*nl(l1,d=1)\n",
    "    w+=np.dot(x.T,grad)\n",
    "l1    \n",
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x,d=0):\n",
    "    if d:return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,0,1,1]]).T\n",
    "w=np.random.random((3,1))\n",
    "for i in range(10000):\n",
    "    l1=nl(np.dot(x,w))\n",
    "    loss=y-l1\n",
    "    grad=loss*nl(l1,d=1)\n",
    "    w+=np.dot(x.T,grad)\n",
    "l1    \n",
    "#3 \n",
    "nl(l1,d=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Layers Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  0.5007555904730444\n",
      "Error:  0.051402104544761094\n",
      "Error:  0.028128406158195597\n",
      "Error:  0.02117897890049429\n",
      "Error:  0.017589205474840577\n",
      "Error:  0.01532395906649446\n",
      "Error:  0.013734261035357884\n",
      "Error:  0.0125422366549304\n",
      "Error:  0.011606950012091555\n",
      "Error:  0.010848484878825664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01060591],\n",
       "       [0.99014355],\n",
       "       [0.98991664],\n",
       "       [0.01032771]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nl(x, diff=False):\n",
    "    if diff:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "Y = np.array([[0,1,1,0]]).T\n",
    "W0 = 2 * np.random.random((3,4)) - 1\n",
    "W1 = 2 * np.random.random((4,1)) - 1\n",
    "for i in range(10000):\n",
    "    l0=X\n",
    "    l1=nl(np.dot(l0, W0))\n",
    "    l2=nl(np.dot(l1, W1))\n",
    "\n",
    "    l2err = Y-l2\n",
    "    l2grd = l2err * nl(l2, diff=True)\n",
    "    \n",
    "    l1err = np.dot(l2grd, W1.T)\n",
    "    l1grd = l1err * nl(l1, diff=True)\n",
    "    \n",
    "    W1 += np.dot(l1.T, l2grd)\n",
    "    W0 += np.dot(l0.T, l1grd)\n",
    "    \n",
    "    if (i % 1000) == 0:\n",
    "        print(\"Error: \", str(np.mean(np.abs(l2err))))\n",
    "\n",
    "l2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01181094],\n",
       "       [0.99294058],\n",
       "       [0.98800711],\n",
       "       [0.00966764]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x,d=0):\n",
    "    if d:return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array(([[0,1,1,0]])).T\n",
    "w0=np.random.random((3,4))\n",
    "w1=np.random.random((4,1))\n",
    "for i in range(10000):\n",
    "    l0=x\n",
    "    l1=nl(np.dot(l0,w0))\n",
    "    l2=nl(np.dot(l1,w1))\n",
    "    \n",
    "    l2err=y-l2\n",
    "    l2grd=l2err*nl(l2,d=1)\n",
    "    \n",
    "    l1err=l2grd.dot(w1.T)\n",
    "    l1grd=l1err*nl(l1,d=1)\n",
    "    \n",
    "    w1+=np.dot(l1.T,l2grd)\n",
    "    w0+=np.dot(l0.T,l1grd)\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00568759],\n",
       "       [0.98897092],\n",
       "       [0.99016974],\n",
       "       [0.01141925]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "def nl(x,d=0):\n",
    "    if d:return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "w0=np.random.random((3,4))\n",
    "w1=np.random.random((4,1))\n",
    "for i in range(10000):\n",
    "    l1=nl(np.dot(x,w0))\n",
    "    l2=nl(np.dot(l1,w1))\n",
    "    l2d=(y-l2)*nl(l2,d=1)\n",
    "    l1d=l2d.dot(w1.T)*nl(l1,d=1)\n",
    "    w1+=np.dot(l1.T,l2d)\n",
    "    w0+=np.dot(x.T,l1d)\n",
    "l2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00625963],\n",
       "       [0.98513158],\n",
       "       [0.98616131],\n",
       "       [0.01753937]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "w0=np.random.random((3,4))\n",
    "w1=np.random.random((4,1))\n",
    "for i in range(10000):\n",
    "    l1=1/(1+np.exp(-np.dot(x,w0)))\n",
    "    l2=1/(1+np.exp(-np.dot(l1,w1)))\n",
    "    l2d=(y-l2)*(l2*(1-l2))\n",
    "    l1d=l2d.dot(w1.T)*(l1*(1-l1))\n",
    "    w1+=np.dot(l1.T,l2d)\n",
    "    w0+=np.dot(x.T,l1d)\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00395598],\n",
       "       [0.9846429 ],\n",
       "       [0.98346767],\n",
       "       [0.01862739]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "w0=np.random.random((3,4))\n",
    "w1=np.random.random((4,1))\n",
    "for i in range(10000):\n",
    "    l1=1/(1+np.exp(-np.dot(x,w0)))\n",
    "    l2=1/(1+np.exp(-np.dot(l1,w1)))\n",
    "    l2d=(y-l2)*(l2*(1-l2))\n",
    "    l1d=l2d.dot(w1.T)*(l1*(1-l1))\n",
    "    w1+=np.dot(l1.T,l2d)\n",
    "    w0+=np.dot(x.T,l1d)\n",
    "l2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0094719 ],\n",
       "       [0.99036879],\n",
       "       [0.98933498],\n",
       "       [0.01090529]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "x=np.array([[0,0,1],[1,0,1],[0,1,1],[1,1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "w0=np.random.random((3,4))\n",
    "w1=np.random.random((4,1))\n",
    "for i in range(10000):\n",
    "    l1=1/(1+np.exp(-np.dot(x,w0)))\n",
    "    l2=1/(1+np.exp(-np.dot(l1,w1)))\n",
    "    l2d=(y-l2)*l2*(1-l2)\n",
    "    l1d=l2d.dot(w1.T)*l1*(1-l1)\n",
    "    w1+=np.dot(l1.T,l2d)\n",
    "    w0+=np.dot(x.T,l1d)\n",
    "l2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
